{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNERDdS/E9iETngcubyY9jn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Bishu-21/FastSearch50K/blob/main/FastSearch50K.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DcZw3hKHnl1y",
        "outputId": "c5deb7b0-39b5-4141-cfee-2efc83518451"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded 50000 documents.\n",
            "Query Time: 47.29 ms\n",
            "[1] (0.655) ‚Üí Document number 1 about machine learning, AI, and data science.\n",
            "[2] (0.655) ‚Üí Document number 2 about machine learning, AI, and data science.\n",
            "[3] (0.655) ‚Üí Document number 3 about machine learning, AI, and data science.\n",
            "[4] (0.655) ‚Üí Document number 4 about machine learning, AI, and data science.\n",
            "[5] (0.655) ‚Üí Document number 5 about machine learning, AI, and data science.\n"
          ]
        }
      ],
      "source": [
        "# üõ† Install necessary packages\n",
        "!pip install -q scikit-learn nltk\n",
        "\n",
        "# üìö Import libraries\n",
        "import numpy as np\n",
        "import time\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "import os\n",
        "\n",
        "# üìÅ Generate or load 50k documents\n",
        "if not os.path.exists('docs.txt'):\n",
        "    with open('docs.txt', 'w') as f:\n",
        "        for i in range(50000):\n",
        "            f.write(f\"Document number {i} about machine learning, AI, and data science.\\n\")\n",
        "\n",
        "# üì• Read the documents\n",
        "with open('docs.txt', 'r') as f:\n",
        "    documents = [line.strip() for line in f.readlines()]\n",
        "\n",
        "print(f\"Loaded {len(documents)} documents.\")\n",
        "\n",
        "# üßπ Preprocessing function\n",
        "stop_words = set(stopwords.words('english'))\n",
        "def preprocess(text):\n",
        "    tokens = text.lower().split()\n",
        "    return ' '.join([word for word in tokens if word not in stop_words])\n",
        "\n",
        "cleaned_docs = [preprocess(doc) for doc in documents]\n",
        "\n",
        "# üß† Build TF-IDF vector space\n",
        "vectorizer = TfidfVectorizer(max_features=50000)\n",
        "doc_vectors = vectorizer.fit_transform(cleaned_docs)\n",
        "\n",
        "# üîç Fast search function\n",
        "def search(query, top_k=5):\n",
        "    start = time.time()\n",
        "    query_vec = vectorizer.transform([preprocess(query)])\n",
        "    similarities = cosine_similarity(query_vec, doc_vectors).flatten()\n",
        "    ranked_indices = np.argsort(similarities)[::-1][:top_k]\n",
        "    results = [(i, documents[i], round(similarities[i], 3)) for i in ranked_indices]\n",
        "    end = time.time()\n",
        "    print(f\"Query Time: {(end - start) * 1000:.2f} ms\")\n",
        "    return results\n",
        "\n",
        "# üöÄ Run a sample query\n",
        "results = search(\"machine learning and AI\")\n",
        "for idx, doc, score in results:\n",
        "    print(f\"[{idx}] ({score}) ‚Üí {doc}\")"
      ]
    }
  ]
}